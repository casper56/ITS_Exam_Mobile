# ITS AI 核心能力技術重點筆記 (ITS_AI_TECH.md)

本文件整理自 `www/ITS_AI/questions_ITS_AI.json`，涵蓋 AI 核心能力考試中的關鍵專有名詞、概念解釋及其對應的題目 ID。並於每個詞彙下方補充網路搜尋與系統性的觀念介紹。

---
## 0. 系統性觀念導讀 (Systematic Introduction)

在深入各項專有名詞前，必須先了解人工智慧領域的「俄羅斯娃娃」層級架構：
*   **人工智慧 (AI)**：最外層的概念，是一個廣泛的電腦科學領域，旨在讓電腦系統模擬人類的思考、學習與解決問題的能力。
*   **機器學習 (ML)**：AI 的子集。不透過硬編碼（Hard-coding）給定所有規則，而是讓電腦透過演算法從海量「數據」中自我學習，歸納出模式來進行預測。
*   **深度學習 (DL)**：ML 的子集。使用多層次的「人工神經網路」(Artificial Neural Networks) 來處理極度複雜的非結構化數據（如影像、聲音、自然語言）。大語言模型 (LLM) 即奠基於此。

---

## 1. 機器學習基本類型 (Learning Types)

### 監督式學習 (Supervised Learning)
*   **定義**：使用標記過的資料（Labeled Data）進行訓練，模型學習輸入與輸出（標籤）之間的對應關係。
*   **常見任務**：分類 (Classification)、迴歸 (Regression)。
*   **相關 ID**：11, 18, 47, 72, 105
*   > **🌐 網路訊息補充：** 
    > 監督式學習就像是「有標準答案的考試」。我們提供大量已經有答案（標籤）的考古題給模型練習。系統性來說，它是最成熟且應用最廣泛的機器學習方式。核心挑戰在於取得高品質的標註資料，以及避免模型「死背答案」（過度擬合）。

### 非監督式學習 (Unsupervised Learning)
*   **定義**：使用未標記的資料（Unlabeled Data）進行訓練，模型試圖找出資料內部的隱藏結構或模式。
*   **常見任務**：叢集 (Clustering)、降維 (Dimensionality Reduction, 如 PCA)。
*   **相關 ID**：10, 11, 18, 47, 86, 105, 108
*   > **🌐 網路訊息補充：** 
    > 非監督式學習就像是「沒有標準答案的分類遊戲」。模型必須自己觀察資料的特徵，做到「物以類聚」。在系統架構中，常用於前期的資料探索、客戶分群（如市場行銷）、或是異常偵測（找出行群中特立獨行的點）。

### 增強式學習 (Reinforcement Learning)
*   **定義**：透過智慧體（Agent）與環境互動，根據獲得的獎勵（Reward）或懲罰（Penalty）來調整策略，以達成目標。常用於遊戲 AI、機器人控制。
*   **相關 ID**：12, 72
*   > **🌐 網路訊息補充：** 
    > 增強式學習如同「訓練寵物」。做對了給獎勵，做錯了給懲罰。系統性而言，它不需要預先準備資料集，而是在虛擬環境中透過無數次的「試錯 (Trial and Error)」來找到利益最大化的策略（Policy）。知名應用如自駕車的決策系統或 AlphaGo。

---

## 2. 核心演算法與模型 (Models & Algorithms)

### 決策樹 (Decision Tree)
*   **特點**：以樹狀結構進行決策，具有極高的**可解釋性**（Interpretable）。透過一系列特徵判斷將資料切割成子集。
*   **應用**：可用於分類與迴歸。
*   **防止過擬合**：限制樹深 (Max Depth)、設定葉節點最少樣本數。
*   **相關 ID**：1, 6, 35, 72, 85, 86, 95, 96, 97
*   > **🌐 網路訊息補充：** 
    > 系統上，決策樹是「白箱模型 (White-box Model)」的代表，適合需要向非技術人員（如醫療、金融人員）解釋決策原因的場景。其進階變體如「隨機森林 (Random Forest)」和「XGBoost」透過組合多棵樹來解決決策樹容易過度擬合的問題，是業界極愛用的表格資料演算法。

### 支援向量機 (SVM, Support Vector Machine)
*   **特點**：尋找一個最佳超平面來區隔不同類別，通常被視為**黑箱模型**，解釋性較差。
*   **相關 ID**：1, 86
*   > **🌐 網路訊息補充：** 
    > SVM 的核心思想是在空間中畫出一條（或多維的超平面）最寬的「楚河漢界」，讓不同類別的資料被最安全地分開。在深度學習崛起前，SVM 是分類任務的王者，但在資料量極大時運算成本較高。

### 神經網路 (Neural Network / Deep Learning)
*   **特點**：模仿人腦神經元結構，適合處理複雜非線性問題，通常為黑箱模型。
*   **卷積神經網路 (CNN)**：特別擅長處理影像資料，利用卷積層提取空間特徵。
*   **相關 ID**：1, 9, 108
*   > **🌐 網路訊息補充：** 
    > 神經網路是深度學習的基礎架構。系統包含「輸入層」、「隱藏層」與「輸出層」。其中 CNN (卷積神經網路) 是電腦視覺的核心，利用「卷積層」掃描影像邊緣、紋理；而 RNN/Transformer 則是處理時間序列和語言的核心。它們強大但都是難以解釋運作邏輯的「黑箱」。

### K-Means 叢集 (K-Means Clustering)
*   **特點**：典型的非監督式學習，將相似的資料點歸類到 K 個群組（Clusters）中。
*   **相關 ID**：1, 10, 86
*   > **🌐 網路訊息補充：** 
    > 系統運作上，您必須先決定要分幾群 (K 值)。演算法會隨機丟下 K 個中心點，然後不斷調整這些中心點的位置，尋找群內的最小距離，直到每一群的邊界穩定下來為止。是做客戶分群 (Customer Segmentation) 最經典的演算法。

---

## 3. 資料處理與特徵工程 (Data Engineering)

### 訓練/驗證/測試集 (Train / Validation / Test)
*   **訓練集**：用於模型學習參數。
*   **驗證集**：用於調整**超引數 (Hyperparameters)** 並防止過擬合。
*   **測試集**：用於最終評估模型在未見過資料上的泛化能力。
*   **比例**：常見比例為 80% 訓練, 20% 測試（或 70/15/15）。
*   **相關 ID**：3, 4, 5, 28, 62
*   > **🌐 網路訊息補充：** 
    > 系統性比喻：訓練集是「平時作業」，驗證集是「考前模擬考（老師/工程師可依此調整超引數）」，測試集是「最終大考（只能考一次以評估真實實力）」。嚴格區分這三者是機器學習專案成功的基石，否則會導致資料洩漏 (Data Leakage)。

### 獨熱編碼 (One-Hot Encoding / 一位有效編碼)
*   **定義**：將類別型資料（如：車輛型別）轉換為數值向量，每個類別對應一個維度，只有所屬類別為 1，其餘為 0。常用於處理無序的類別特徵。
*   **相關 ID**：27, 60, 61
*   > **🌐 網路訊息補充：** 
    > 機器學習模型只能看懂「數字」。對於沒有大小順序之分的類別（如：台北、台中、高雄），如果直接標為 1, 2, 3，模型會誤以為高雄 > 台北。One-Hot Encoding 透過擴增欄位 (台北:[1,0,0], 台中:[0,1,0]...) 解決此問題，缺點是資料維度（欄位數）會大幅增加。

### 標籤編碼 (Label Encoding)
*   **定義**：將類別映射為唯一的整數（如：學士=1, 碩士=2）。
*   **相關 ID**：27
*   > **🌐 網路訊息補充：** 
    > 適用於有「順序關係 (Ordinal)」的類別資料。例如教育程度、滿意度調查（非常不滿意=1, 不滿意=2...）。這樣編碼可以讓演算法合理地學習到數值之間大小的隱含關係。

### 主成分分析 (PCA)
*   **定義**：降維技術，透過線性變換減少特徵維度，同時保留最大變異量。
*   **相關 ID**：61, 86
*   > **🌐 網路訊息補充：** 
    > 當資料特徵過多（維度災難）時，PCA 可以在「損失最少核心資訊」的前提下，把 100 個欄位壓縮成 10 個核心欄位（主成分）。這不僅能加速模型訓練，還能用於將高維資料轉為 2D/3D 以進行視覺化。

### 特徵縮放 (Feature Scaling / 標準化)
*   **原因**：當特徵範圍差異極大時（如 0-1 與 0-10000），會影響 KNN 或梯度下降的效能。
*   **相關 ID**：103
*   > **🌐 網路訊息補充：** 
    > 常見的方法有「正規化 (Normalization, 縮放到 0~1)」和「標準化 (Standardization, 平均值為0, 標準差為1)」。這確保了模型在學習時，不會因為某個特徵（如年薪數字很大）而產生權重偏誤，忽略了其他特徵（如年齡數字很小）。

---

## 4. 模型評估指標 (Evaluation Metrics)

### 分類指標 (Classification Metrics)
*   **準確率 (Accuracy)**：所有預測中正確的比例。但在資料不平衡時可能誤導。
*   **精確率 (Precision / 查準率)**：預測為正例中，實際為正例的比例。
*   **召回率 (Recall / 查全率)**：實際為正例中，被正確預測出來的比例。
*   **F1 分數 (F1-Score)**：精確率與召回率的調和平均數，適合處理不平衡資料。
*   **混淆矩陣 (Confusion Matrix)**：顯示 TP, FP, TN, FN 數量的表格。
*   **相關 ID**：29, 33, 34, 40, 67, 104
*   > **🌐 網路訊息補充：** 
    > 系統思維中，沒有絕對好的單一指標。在「資料不平衡」(如詐騙偵測，99%正常，1%詐騙) 下，Accuracy 是無效的（全猜正常也有99%）。此時需要看 Recall (寧可錯殺一百不可放過一個，適用醫療診斷/詐騙) 或 Precision (發送行銷郵件，預測會買才寄以省成本)，F1-Score 則是兩者的平衡妥協。

### 迴歸指標 (Regression Metrics)
*   **均方根誤差 (RMSE)**：預測值與真實值差距的平均大小，越小越好。
*   **平均絕對誤差 (MAE)**：預測誤差的絕對值平均。
*   **R 平方 (R-Squared)**：衡量模型擬合度，越接近 1 越好。
*   **相關 ID**：32, 104, 112
*   > **🌐 網路訊息補充：** 
    > 迴歸是在預測「連續數字」(如房價)。RMSE 會將誤差平方，所以對於「極端離群值 (Outliers)」會給予極大的懲罰；若你的業務場景容許偶爾的極端誤差，看 MAE 會比較客觀。R平方則是用百分比（0~1）來告訴你模型能解釋多少的資料變異。

---

## 5. 模型問題與優化 (Model Issues)

### 過度擬合 (Overfitting)
*   **現象**：訓練集準確率極高，但測試集表現很差（泛化能力差）。模型學習到了噪聲。
*   **對策**：增加資料量、簡化模型（減少參數/深度）、正則化 (Regularization)、早停法 (Early Stopping)。
*   **相關 ID**：13, 30, 35, 68, 79, 97
*   > **🌐 網路訊息補充：** 
    > 系統性稱之為「高變異 (High Variance)」。模型就像一個死背考古題的學生，連題目上的錯字都背下來了，一遇到沒看過的新題型就考砸。正則化 (限制權重) 和 Dropout (神經網路中隨機關閉神經元) 是最常見的系統解法。

### 低度擬合 (Underfitting / 欠擬合)
*   **現象**：模型過於簡單，無論在訓練集或測試集表現都不佳（高偏差、低方差）。
*   **對策**：增加模型複雜度、增加特徵工程、延長訓練時間。
*   **相關 ID**：30, 66, 95, 97
*   > **🌐 網路訊息補充：** 
    > 系統性稱之為「高偏差 (High Bias)」。模型就像只學了加減法卻被抓去考微積分，能力不足以捕捉資料的複雜規律。解決方案是換用更強大的深層演算法，或是餵給模型更多有價值的特徵（Feature Engineering）。

### 資料偏差 (Bias)
*   **資料收集偏差 (Data Collection Bias)**：取樣過程未能均勻代表母體（如只收富裕社群資料）。
*   **隱含偏見**：即使移除敏感特徵（如收入），相關特徵（如郵遞區號）仍可能導致偏見。
*   **相關 ID**：20, 36, 55, 93
*   > **🌐 網路訊息補充：** 
    > 機器學習有句名言："Garbage In, Garbage Out"。如果訓練資料本身蘊含著人類社會的歷史歧視或採樣不均（如缺乏少數族群影像），AI 就會固化並放大這些偏見。系統層面上需導入「公平性評估工具」來做偏移校正。

### 模型漂移 (Model/Concept Drift)
*   **現象**：生產環境中的資料分佈或變數關係發生變化，導致效能隨時間下降。
*   **對策**：持續監控、重新訓練模型。
*   **相關 ID**：41, 42, 89, 92
*   > **🌐 網路訊息補充：** 
    > 世界是不斷變化的 (例如疫情改變了人類消費習慣)。兩年前訓練得很準的 AI，現在可能因為「資料漂移 (Data Drift, 輸入資料分佈變了)」或「概念漂移 (Concept Drift, 輸入與輸出的邏輯對應關係變了)」而失效。因此 MLOps 系統必須包含「持續監控」與「自動重訓管線」。

---

## 6. AI 應用領域 (Application Domains)

### 電腦視覺 (Computer Vision)
*   **物件偵測 (Object Detection)**：框出物件並標記 (如 YOLO 演算法)。
*   **語義分割 (Semantic Segmentation)**：將每個畫素分類，精確描繪邊界 (如自動駕駛看馬路)。
*   **臉部特徵分析**：分析年齡、情緒，不一定涉及識別身份。
*   **相關 ID**：2, 25, 100, 110
*   > **🌐 網路訊息補充：** 
    > 電腦視覺是讓電腦「看懂」世界的技術。從早期的影像分類 (Image Classification: 整張圖是一隻貓)，演進到物件偵測 (Object Detection: 用框框出貓在哪裡)，再到最細緻的語義分割 (Semantic Segmentation: 把貓的形狀每一個 Pixel 都描繪歸類)，這三者是電腦視覺系統的進化階梯。

### 自然語言處理 (NLP)
*   **情感分析 (Sentiment Analysis)**：判斷情緒（正面/負面），常用於輿情監控。
*   **命名實體辨識 (NER)**：提取特定實體（人名、地點、時間）。
*   **意圖 (Intent)** 與 **實體 (Entity)**：聊天機器人的核心概念。
*   **相關 ID**：7, 24, 84, 101, 109
*   > **🌐 網路訊息補充：** 
    > NLP 旨在讓電腦理解人類語言。在建置交談機器人 (Chatbot) 或語音助理 (如 Siri) 時，系統的 NLP 引擎第一步就是做「意圖識別 (知道你想訂票)」和「實體萃取 (知道你要去倫敦的日期時間)」，萃取成變數後才能觸發後續的系統 API 呼叫。

### 異常偵測 (Anomaly Detection)
*   **應用**：信用卡詐騙偵測、設備故障預警（稀有事件）。
*   **相關 ID**：11, 33, 99
*   > **🌐 網路訊息補充：** 
    > 異常偵測專門尋找「離群值」。在金融和資安系統中，正常行為佔了 99.9% 以上。這類系統不能單靠傳統分類演算法，通常會結合統計模型或非監督式學習（如 Isolation Forest）來框出正常的輪廓，落在輪廓外的就直接發出警報。

---

## 7. 負責任 AI (Responsible AI Principles)

*   **公平性 (Fairness)**：不因種族、性別等因素歧視。
*   **可靠性與安全性 (Reliability & Safety)**：系統在各種情況下應穩定執行，不傷人。
*   **隱私權與安全性 (Privacy & Security)**：保護使用者資料。
*   **包容性 (Inclusiveness)**：讓所有人（含身障者）受益。
*   **透明度 (Transparency)**：模型可解釋、決策過程公開。
*   **責任歸屬 (Accountability)**：誰該為 AI 的決策負責。
*   **相關 ID**：15, 44, 91, 102, 111
*   > **🌐 網路訊息補充：** 
    > 這是微軟 (Microsoft Azure) 及各大科技巨頭推動的核心準則。隨著 AI 深入社會基礎設施，確保 AI 的決策不帶歧視 (公平性)、不洩漏個資並防範攻擊 (隱私/安全性)、在自駕車等關鍵應用中穩定不當機 (可靠性)，以及在出錯時知道誰該負責 (責任歸屬)，是現代 AI 系統工程師必備的法律與道德系統框架。

---

## 8. 專有名詞補充

*   **推斷 (Inference)**：使用訓練好的模型進行預測的過程。 (ID 40)
    > **🌐 補充：** 系統流程分為「訓練 (Training, 極度耗時耗算力)」和「推斷 (Inference, 講求即時快速)」。模型上線後我們稱之為處於推斷 (Inference) 階段。
*   **AutoML (自動化機器學習)**：自動嘗試多種演算法與超引數以找出最佳模型。 (ID 105)
    > **🌐 補充：** 將資料科學家尋找最佳特徵、最佳演算法的「反覆試錯過程」完全自動化的雲端系統平台。
*   **容器化 (Docker)**：確保執行環境一致性，利於雲端與邊緣部署。 (ID 106)
    > **🌐 補充：** 把 AI 程式碼、依賴套件和作業系統環境「打包成一個獨立貨櫃」。保證在工程師電腦上能跑的 AI 模型，丟到雲端伺服器上也能一模一樣地跑。
*   **邊緣部署 (Edge Deployment)**：將模型放在設備終端以達成極低延遲（如 15ms 預測）。 (ID 90)
    > **🌐 補充：** 不把資料傳回雲端，而是直接在手機、IoT 設備、工廠機器上執行 AI 推斷，節省網路頻寬並保障隱私。
*   **BLEU**：評估機器翻譯品質的指標。 (ID 33)
    > **🌐 補充：** 系統透過比對 AI 翻譯出來的字詞與人類專業翻譯的字詞重合度，來給出 0~1 的自動化評分標準。

---

## 9. 其他重要概念 (Other Important Concepts)

*   **決策陳述式 (Decision Statements)**：當問題邏輯簡單（如 10 個是非題）時，傳統的 `if-else` 可能比 AI 更高效、易維護。 (ID 9)
*   **領域專家 (Domain Experts)**：雖然不懂 AI 技術，但擁有特定行業知識，能協助挑選特徵、定義目標、評估有效性。 (ID 14, 26, 73)
*   **資料協作 (Data Collaboration)**：不同組織（公私部門、政府）共享資料以解決公共問題。 (ID 53)
*   **API (應用程式介面)**：以結構化、規範化的方式從社群平台大規模收集資料的最佳途徑。 (ID 54)
*   **可擴展性 (Scalability)**：當用戶數暴增（如 10 倍）時，預測速度是否能跟上，是部署時的關鍵考量。 (ID 98)
*   **推斷調整 (Inference Tuning)** 與 **健康監視 (Health Monitoring)**：生產環境中運維 (MLOps) 的核心工作。 (ID 81)
*   **A/B 測試**：將不同演算法版本推送給不同用戶群以比較效果。 (ID 82, 43)
    > **🌐 補充：** 在電商推薦系統中極為重要。將舊版模型給 50% 流量，新版給 50% 流量，直接用真實的商業轉化率來決定誰勝出，而不是只看工程實驗室裡的指標。